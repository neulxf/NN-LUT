from transformers import AutoConfig
import pandas as pd
from tqdm import tqdm

# å®šä¹‰è¦åˆ†æçš„æ¨¡å‹åˆ—è¡¨
MODELS_TO_ANALYZE = [
    # Qwenç³»åˆ—
    "Qwen/Qwen2.5-0.5B",
    "Qwen/Qwen2.5-1.5B", 
    "Qwen/Qwen2.5-7B",
    "Qwen/Qwen2.5-72B",
    "Qwen/Qwen2.5-Math-7B",
	"Qwen/Qwen2.5-3B-Instruct",
	"Qwen/Qwen2.5-3B",
    
    # LLaMAç³»åˆ—
    "meta-llama/Llama-2-7b-hf",
    "meta-llama/Llama-2-13b-hf",
    "meta-llama/Llama-3-8b",
    "meta-llama/Llama-3-70b",
	"meta-llama/Llama-3.2-3B",
	"meta-llama/Llama-3.2-1B",
	
    
    # GPTç³»åˆ—
    "gpt2",
    "gpt2-medium",
    "gpt2-large",
    "gpt2-xl",
    "openai-community/gpt2",
    
    # BERTç³»åˆ—
    "bert-base-uncased",
    "bert-large-uncased",
    "bert-base-cased", 
    "bert-large-cased",
    
    # Gemmaç³»åˆ—
    "google/gemma-2b",
    "google/gemma-7b",
    "google/gemma-2-2b",
    "google/gemma-2-9b",
    
    # SmolLMç³»åˆ—ï¼ˆé€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ¨¡å‹ï¼‰
    "HuggingFaceTB/SmolLM-135M",
    "HuggingFaceTB/SmolLM-360M", 
    "HuggingFaceTB/SmolLM-1.7B",
    "HuggingFaceTB/SmolLM3-3B",
    
    # TinyLLaMAç³»åˆ—
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "TinyLlama/TinyLlama-1.1B-intermediate-step-715k-1.5T",
	"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",

	# OLMoç³»åˆ—
	"allenai/OLMo-1B",
	"allenai/OLMo-1B-7B",

	# OpenELMç³»åˆ—
	"apple/OpenELM-1_1B",
	"apple/OpenELM-3B",

	# Pythiaç³»åˆ—
	"EleutherAI/pythia-14m",
	"EleutherAI/pythia-70m",
	"EleutherAI/pythia-160m",
	"EleutherAI/pythia-410m",
	"EleutherAI/pythia-1b",
	"EleutherAI/pythia-1.4b",
	"EleutherAI/pythia-2.8b",

	# RedPajamaç³»åˆ—
	"togethercomputer/RedPajama-INCITE-Base-3B-v1",

	# Phi-2ç³»åˆ—
	"microsoft/phi-2",

	"facebook/opt-125m",
	"facebook/opt-350m",
	"facebook/opt-1.3b",
	"facebook/opt-2.7b",
	"facebook/opt-6.7b",
	"facebook/opt-13b",
	"facebook/opt-30b",
	"facebook/opt-66b",
	"facebook/opt-175b",
	"facebook/opt-330b",
	"facebook/opt-660b",
	"facebook/opt-1320b",
]

def get_model_info(model_name):
    """è·å–å•ä¸ªæ¨¡å‹çš„é…ç½®ä¿¡æ¯"""
    try:
        config = AutoConfig.from_pretrained(model_name)
        
        info = {
            'model_name': model_name,
            'num_hidden_layers': getattr(config, 'num_hidden_layers', 'N/A'),
            'hidden_size': getattr(config, 'hidden_size', 'N/A'),
            'num_attention_heads': getattr(config, 'num_attention_heads', 'N/A'),
            'intermediate_size': getattr(config, 'intermediate_size', 'N/A'),
            'vocab_size': getattr(config, 'vocab_size', 'N/A'),
            'max_position_embeddings': getattr(config, 'max_position_embeddings', 'N/A'),
            'architecture': getattr(config, 'architectures', ['N/A'])[0] if getattr(config, 'architectures', None) else 'N/A'
        }
        
        # å¯¹äº GPT-2 å’Œ OPT æ¨¡å‹ï¼Œå¦‚æœ intermediate_size ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¯”ä¾‹ 4x
        if info['intermediate_size'] == 'N/A' and info['hidden_size'] != 'N/A':
            architecture = info['architecture'].lower()
            if 'gpt2' in architecture or 'opt' in architecture:
                # GPT-2 å’Œ OPT æ¨¡å‹é€šå¸¸ä½¿ç”¨ 4x hidden_size ä½œä¸º FFN ç»´åº¦
                info['intermediate_size'] = info['hidden_size'] * 4
                info['ffn_hidden_ratio'] = 4.0
            else:
                # å°è¯•å…¶ä»–å¯èƒ½çš„å±æ€§å
                info['intermediate_size'] = getattr(config, 'ffn_dim', 
                                                   getattr(config, 'ffn_hidden_size', 
                                                          getattr(config, 'd_ff', 'N/A')))
                if info['intermediate_size'] != 'N/A' and info['hidden_size'] != 'N/A':
                    info['ffn_hidden_ratio'] = round(info['intermediate_size'] / info['hidden_size'], 4)
                else:
                    info['ffn_hidden_ratio'] = 'N/A'
        # è®¡ç®—FFNä¸éšè—ç»´åº¦çš„æ¯”ä¾‹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰è®¡ç®—ï¼‰
        elif info['intermediate_size'] != 'N/A' and info['hidden_size'] != 'N/A':
            info['ffn_hidden_ratio'] = round(info['intermediate_size'] / info['hidden_size'], 4)
        else:
            info['ffn_hidden_ratio'] = 'N/A'
            
        # è®¡ç®—æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦
        if info['hidden_size'] != 'N/A' and info['num_attention_heads'] != 'N/A':
            info['head_dim'] = info['hidden_size'] // info['num_attention_heads']
        else:
            info['head_dim'] = 'N/A'
            
        return info
        
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹ {model_name} ä¿¡æ¯å¤±è´¥: {e}")
        return {
            'model_name': model_name,
            'num_hidden_layers': 'Error',
            'hidden_size': 'Error', 
            'num_attention_heads': 'Error',
            'intermediate_size': 'Error',
            'vocab_size': 'Error',
            'max_position_embeddings': 'Error',
            'architecture': 'Error',
            'ffn_hidden_ratio': 'Error',
            'head_dim': 'Error'
        }

def analyze_models():
    """æ‰¹é‡åˆ†ææ‰€æœ‰æ¨¡å‹"""
    print("ğŸš€ å¼€å§‹æ‰¹é‡è·å–æ¨¡å‹ä¿¡æ¯...")
    print("=" * 80)
    
    results = []
    
    # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºè¿›åº¦
    for model_name in tqdm(MODELS_TO_ANALYZE, desc="åˆ†ææ¨¡å‹ä¸­"):
        model_info = get_model_info(model_name)
        results.append(model_info)
    
    # è½¬æ¢ä¸ºDataFrameä¾¿äºåˆ†æ
    df = pd.DataFrame(results)
    
    # ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
    df.to_csv('model_analysis.csv', index=False)
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° model_analysis.csv")
    
    return df

def print_detailed_comparison(df):
    """æ‰“å°è¯¦ç»†çš„æ¯”è¾ƒç»“æœ"""
    print("\n" + "="*100)
    print("ğŸ“Š æ¨¡å‹ç»“æ„å‚æ•°è¯¦ç»†æ¯”è¾ƒ")
    print("="*100)
    
    # æŒ‰æ¨¡å‹ç³»åˆ—åˆ†ç»„æ˜¾ç¤º
    series_groups = {
        'Qwen': [m for m in MODELS_TO_ANALYZE if 'qwen' in m.lower()],
        'LLaMA': [m for m in MODELS_TO_ANALYZE if 'llama' in m.lower()],
        'GPT': [m for m in MODELS_TO_ANALYZE if 'gpt' in m.lower()],
        'BERT': [m for m in MODELS_TO_ANALYZE if 'bert' in m.lower()],
        'Gemma': [m for m in MODELS_TO_ANALYZE if 'gemma' in m.lower()],
        'SmolLM': [m for m in MODELS_TO_ANALYZE if 'smol' in m.lower()],
        'TinyLLaMA': [m for m in MODELS_TO_ANALYZE if 'tiny' in m.lower()]
    }
    
    for series_name, series_models in series_groups.items():
        if not series_models:
            continue
            
        print(f"\nğŸ” {series_name} ç³»åˆ—:")
        print("-" * 80)
        
        series_df = df[df['model_name'].isin(series_models)]
        
        for _, row in series_df.iterrows():
            if row['num_hidden_layers'] == 'Error':
                print(f"   {row['model_name']}: è·å–å¤±è´¥")
                continue
                
            print(f"   ğŸ“ {row['model_name']}")
            print(f"      å±‚æ•°: {row['num_hidden_layers']:>3} | "
                  f"éšè—ç»´åº¦: {row['hidden_size']:>5} | "
                  f"æ³¨æ„åŠ›å¤´: {row['num_attention_heads']:>3} | "
                  f"å¤´ç»´åº¦: {row['head_dim']:>3}")
            print(f"      FFNç»´åº¦: {row['intermediate_size']:>6} | "
                  f"FFN/éšè—æ¯”ä¾‹: {row['ffn_hidden_ratio']:>5} | "
                  f"è¯è¡¨å¤§å°: {row['vocab_size']:>6}")
            print(f"      æœ€å¤§é•¿åº¦: {row['max_position_embeddings']:>5} | "
                  f"æ¶æ„: {row['architecture']}")

def print_summary_statistics(df):
    """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
    print("\n" + "="*100)
    print("ğŸ“ˆ ç»Ÿè®¡æ‘˜è¦")
    print("="*100)
    
    # è¿‡æ»¤æ‰é”™è¯¯çš„æ•°æ®
    valid_df = df[df['num_hidden_layers'] != 'Error']
    
    if len(valid_df) == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯åˆ†æ")
        return
    
    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
    numeric_cols = ['num_hidden_layers', 'hidden_size', 'num_attention_heads', 
                    'intermediate_size', 'vocab_size', 'max_position_embeddings', 'ffn_hidden_ratio']
    
    for col in numeric_cols:
        valid_df[col] = pd.to_numeric(valid_df[col], errors='coerce')
    
    stats = valid_df.describe()
    print(stats.round(2))

# ä¸»æ‰§è¡Œå‡½æ•°
if __name__ == "__main__":
    # æ‰§è¡Œåˆ†æ
    df = analyze_models()
    
    # æ˜¾ç¤ºè¯¦ç»†æ¯”è¾ƒ
    print_detailed_comparison(df)
    
    # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
    print_summary_statistics(df)
    
    # ä¿å­˜ç¾åŒ–åçš„æ–‡æœ¬æŠ¥å‘Š
    with open('model_analysis_report.txt', 'w', encoding='utf-8') as f:
        f.write("æ¨¡å‹ç»“æ„å‚æ•°åˆ†ææŠ¥å‘Š\n")
        f.write("="*50 + "\n")
        for _, row in df.iterrows():
            if row['num_hidden_layers'] != 'Error':
                f.write(f"\næ¨¡å‹: {row['model_name']}\n")
                f.write(f"  å±‚æ•°: {row['num_hidden_layers']}\n")
                f.write(f"  éšè—ç»´åº¦: {row['hidden_size']}\n")
                f.write(f"  æ³¨æ„åŠ›å¤´æ•°: {row['num_attention_heads']}\n")
                f.write(f"  FFNç»´åº¦: {row['intermediate_size']}\n")
                f.write(f"  FFN/éšè—æ¯”ä¾‹: {row['ffn_hidden_ratio']}\n")
                f.write(f"  è¯è¡¨å¤§å°: {row['vocab_size']}\n")
                f.write(f"  æœ€å¤§é•¿åº¦: {row['max_position_embeddings']}\n")
    
    print(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° model_analysis_report.txt")