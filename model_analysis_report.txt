模型结构参数分析报告
==================================================

模型: Qwen/Qwen2.5-0.5B
  层数: 24
  隐藏维度: 896
  注意力头数: 14
  FFN维度: 4864
  FFN/隐藏比例: 5.4286
  词表大小: 151936
  最大长度: 32768

模型: Qwen/Qwen2.5-1.5B
  层数: 28
  隐藏维度: 1536
  注意力头数: 12
  FFN维度: 8960
  FFN/隐藏比例: 5.8333
  词表大小: 151936
  最大长度: 131072

模型: Qwen/Qwen2.5-7B
  层数: 28
  隐藏维度: 3584
  注意力头数: 28
  FFN维度: 18944
  FFN/隐藏比例: 5.2857
  词表大小: 152064
  最大长度: 131072

模型: Qwen/Qwen2.5-72B
  层数: 80
  隐藏维度: 8192
  注意力头数: 64
  FFN维度: 29568
  FFN/隐藏比例: 3.6094
  词表大小: 152064
  最大长度: 131072

模型: Qwen/Qwen2.5-Math-7B
  层数: 28
  隐藏维度: 3584
  注意力头数: 28
  FFN维度: 18944
  FFN/隐藏比例: 5.2857
  词表大小: 152064
  最大长度: 4096

模型: Qwen/Qwen2.5-3B-Instruct
  层数: 36
  隐藏维度: 2048
  注意力头数: 16
  FFN维度: 11008
  FFN/隐藏比例: 5.375
  词表大小: 151936
  最大长度: 32768

模型: Qwen/Qwen2.5-3B
  层数: 36
  隐藏维度: 2048
  注意力头数: 16
  FFN维度: 11008
  FFN/隐藏比例: 5.375
  词表大小: 151936
  最大长度: 32768

模型: meta-llama/Llama-2-7b-hf
  层数: 32
  隐藏维度: 4096
  注意力头数: 32
  FFN维度: 11008
  FFN/隐藏比例: 2.6875
  词表大小: 32000
  最大长度: 4096

模型: meta-llama/Llama-2-13b-hf
  层数: 40
  隐藏维度: 5120
  注意力头数: 40
  FFN维度: 13824
  FFN/隐藏比例: 2.7
  词表大小: 32000
  最大长度: 4096

模型: meta-llama/Llama-3.2-3B
  层数: 28
  隐藏维度: 3072
  注意力头数: 24
  FFN维度: 8192
  FFN/隐藏比例: 2.6667
  词表大小: 128256
  最大长度: 131072

模型: meta-llama/Llama-3.2-1B
  层数: 16
  隐藏维度: 2048
  注意力头数: 32
  FFN维度: 8192
  FFN/隐藏比例: 4.0
  词表大小: 128256
  最大长度: 131072

模型: gpt2
  层数: 12
  隐藏维度: 768
  注意力头数: 12
  FFN维度: 3072
  FFN/隐藏比例: 4.0
  词表大小: 50257
  最大长度: 1024

模型: gpt2-medium
  层数: 24
  隐藏维度: 1024
  注意力头数: 16
  FFN维度: 4096
  FFN/隐藏比例: 4.0
  词表大小: 50257
  最大长度: 1024

模型: gpt2-large
  层数: 36
  隐藏维度: 1280
  注意力头数: 20
  FFN维度: 5120
  FFN/隐藏比例: 4.0
  词表大小: 50257
  最大长度: 1024

模型: gpt2-xl
  层数: 48
  隐藏维度: 1600
  注意力头数: 25
  FFN维度: 6400
  FFN/隐藏比例: 4.0
  词表大小: 50257
  最大长度: 1024

模型: openai-community/gpt2
  层数: 12
  隐藏维度: 768
  注意力头数: 12
  FFN维度: 3072
  FFN/隐藏比例: 4.0
  词表大小: 50257
  最大长度: 1024

模型: bert-base-uncased
  层数: 12
  隐藏维度: 768
  注意力头数: 12
  FFN维度: 3072
  FFN/隐藏比例: 4.0
  词表大小: 30522
  最大长度: 512

模型: bert-large-uncased
  层数: 24
  隐藏维度: 1024
  注意力头数: 16
  FFN维度: 4096
  FFN/隐藏比例: 4.0
  词表大小: 30522
  最大长度: 512

模型: bert-base-cased
  层数: 12
  隐藏维度: 768
  注意力头数: 12
  FFN维度: 3072
  FFN/隐藏比例: 4.0
  词表大小: 28996
  最大长度: 512

模型: bert-large-cased
  层数: 24
  隐藏维度: 1024
  注意力头数: 16
  FFN维度: 4096
  FFN/隐藏比例: 4.0
  词表大小: 28996
  最大长度: 512

模型: google/gemma-2b
  层数: 18
  隐藏维度: 2048
  注意力头数: 8
  FFN维度: 16384
  FFN/隐藏比例: 8.0
  词表大小: 256000
  最大长度: 8192

模型: google/gemma-7b
  层数: 28
  隐藏维度: 3072
  注意力头数: 16
  FFN维度: 24576
  FFN/隐藏比例: 8.0
  词表大小: 256000
  最大长度: 8192

模型: google/gemma-2-2b
  层数: 26
  隐藏维度: 2304
  注意力头数: 8
  FFN维度: 9216
  FFN/隐藏比例: 4.0
  词表大小: 256000
  最大长度: 8192

模型: google/gemma-2-9b
  层数: 42
  隐藏维度: 3584
  注意力头数: 16
  FFN维度: 14336
  FFN/隐藏比例: 4.0
  词表大小: 256000
  最大长度: 8192

模型: HuggingFaceTB/SmolLM-135M
  层数: 30
  隐藏维度: 576
  注意力头数: 9
  FFN维度: 1536
  FFN/隐藏比例: 2.6667
  词表大小: 49152
  最大长度: 2048

模型: HuggingFaceTB/SmolLM-360M
  层数: 32
  隐藏维度: 960
  注意力头数: 15
  FFN维度: 2560
  FFN/隐藏比例: 2.6667
  词表大小: 49152
  最大长度: 2048

模型: HuggingFaceTB/SmolLM-1.7B
  层数: 24
  隐藏维度: 2048
  注意力头数: 32
  FFN维度: 8192
  FFN/隐藏比例: 4.0
  词表大小: 49152
  最大长度: 2048

模型: HuggingFaceTB/SmolLM3-3B
  层数: 36
  隐藏维度: 2048
  注意力头数: 16
  FFN维度: 11008
  FFN/隐藏比例: 5.375
  词表大小: 128256
  最大长度: 65536

模型: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  层数: 22
  隐藏维度: 2048
  注意力头数: 32
  FFN维度: 5632
  FFN/隐藏比例: 2.75
  词表大小: 32000
  最大长度: 2048

模型: TinyLlama/TinyLlama-1.1B-intermediate-step-715k-1.5T
  层数: 22
  隐藏维度: 2048
  注意力头数: 32
  FFN维度: 5632
  FFN/隐藏比例: 2.75
  词表大小: 32000
  最大长度: 2048

模型: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T
  层数: 22
  隐藏维度: 2048
  注意力头数: 32
  FFN维度: 5632
  FFN/隐藏比例: 2.75
  词表大小: 32000
  最大长度: 2048

模型: apple/OpenELM-1_1B
  层数: N/A
  隐藏维度: N/A
  注意力头数: N/A
  FFN维度: N/A
  FFN/隐藏比例: N/A
  词表大小: 32000
  最大长度: N/A

模型: apple/OpenELM-3B
  层数: N/A
  隐藏维度: N/A
  注意力头数: N/A
  FFN维度: N/A
  FFN/隐藏比例: N/A
  词表大小: 32000
  最大长度: N/A

模型: EleutherAI/pythia-14m
  层数: 6
  隐藏维度: 128
  注意力头数: 4
  FFN维度: 512
  FFN/隐藏比例: 4.0
  词表大小: 50304
  最大长度: 2048

模型: EleutherAI/pythia-70m
  层数: 6
  隐藏维度: 512
  注意力头数: 8
  FFN维度: 2048
  FFN/隐藏比例: 4.0
  词表大小: 50304
  最大长度: 2048

模型: EleutherAI/pythia-160m
  层数: 12
  隐藏维度: 768
  注意力头数: 12
  FFN维度: 3072
  FFN/隐藏比例: 4.0
  词表大小: 50304
  最大长度: 2048

模型: EleutherAI/pythia-410m
  层数: 24
  隐藏维度: 1024
  注意力头数: 16
  FFN维度: 4096
  FFN/隐藏比例: 4.0
  词表大小: 50304
  最大长度: 2048

模型: EleutherAI/pythia-1b
  层数: 16
  隐藏维度: 2048
  注意力头数: 8
  FFN维度: 8192
  FFN/隐藏比例: 4.0
  词表大小: 50304
  最大长度: 2048

模型: EleutherAI/pythia-1.4b
  层数: 24
  隐藏维度: 2048
  注意力头数: 16
  FFN维度: 8192
  FFN/隐藏比例: 4.0
  词表大小: 50304
  最大长度: 2048

模型: EleutherAI/pythia-2.8b
  层数: 32
  隐藏维度: 2560
  注意力头数: 32
  FFN维度: 10240
  FFN/隐藏比例: 4.0
  词表大小: 50304
  最大长度: 2048

模型: togethercomputer/RedPajama-INCITE-Base-3B-v1
  层数: 32
  隐藏维度: 2560
  注意力头数: 32
  FFN维度: 10240
  FFN/隐藏比例: 4.0
  词表大小: 50432
  最大长度: 2048

模型: microsoft/phi-2
  层数: 32
  隐藏维度: 2560
  注意力头数: 32
  FFN维度: 10240
  FFN/隐藏比例: 4.0
  词表大小: 51200
  最大长度: 2048

模型: facebook/opt-125m
  层数: 12
  隐藏维度: 768
  注意力头数: 12
  FFN维度: 3072
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048

模型: facebook/opt-350m
  层数: 24
  隐藏维度: 1024
  注意力头数: 16
  FFN维度: 4096
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048

模型: facebook/opt-1.3b
  层数: 24
  隐藏维度: 2048
  注意力头数: 32
  FFN维度: 8192
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048

模型: facebook/opt-2.7b
  层数: 32
  隐藏维度: 2560
  注意力头数: 32
  FFN维度: 10240
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048

模型: facebook/opt-6.7b
  层数: 32
  隐藏维度: 4096
  注意力头数: 32
  FFN维度: 16384
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048

模型: facebook/opt-13b
  层数: 40
  隐藏维度: 5120
  注意力头数: 40
  FFN维度: 20480
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048

模型: facebook/opt-30b
  层数: 48
  隐藏维度: 7168
  注意力头数: 56
  FFN维度: 28672
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048

模型: facebook/opt-66b
  层数: 64
  隐藏维度: 9216
  注意力头数: 72
  FFN维度: 36864
  FFN/隐藏比例: 4.0
  词表大小: 50272
  最大长度: 2048
