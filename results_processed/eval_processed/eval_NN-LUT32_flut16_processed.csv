model,arc_challenge_acc,arc_challenge_acc_norm,arc_easy_acc,arc_easy_acc_norm,boolq_acc,hellaswag_acc,hellaswag_acc_norm,lambada_openai_acc,lambada_openai_perplexity,openbookqa_acc,openbookqa_acc_norm,piqa_acc,piqa_acc_norm,winogrande_acc
llama3.2_1b_baseline,0.3148,0.3677,0.6549,0.6061,0.6385,0.4774,0.637,0.6218,5.7481,0.264,0.374,0.7432,0.7437,0.6006
llama3.2_1b_nnlut,0.291,0.3396,0.6145,0.5669,0.5862,0.4514,0.597,0.6072,6.5637,0.254,0.344,0.7307,0.728,0.618
qwen2.5_0.5b_baseline,0.3046,0.3336,0.6561,0.5888,0.6728,0.4062,0.5246,0.4974,11.7227,0.238,0.344,0.7018,0.704,0.5604
qwen2.5_0.5b_nnlut,0.2978,0.3294,0.6368,0.5724,0.63,0.4097,0.5277,0.4361,16.4652,0.232,0.342,0.6926,0.6872,0.5414
smollm_135m_baseline,0.2543,0.2739,0.4886,0.4373,0.6229,0.3468,0.4192,0.3392,43.7529,0.232,0.334,0.6741,0.6697,0.513
smollm_135m_nnlut,0.256,0.2824,0.4529,0.4024,0.6232,0.3462,0.4213,0.2831,67.455,0.24,0.33,0.6681,0.667,0.5146
smollm_360m_baseline,0.3174,0.3387,0.5636,0.4907,0.4211,0.4272,0.5683,0.5051,10.9997,0.274,0.366,0.7127,0.7078,0.5722
smollm_360m_nnlut,0.3106,0.3396,0.5442,0.4832,0.3936,0.4219,0.5633,0.4593,14.6276,0.23,0.368,0.7122,0.7073,0.562
