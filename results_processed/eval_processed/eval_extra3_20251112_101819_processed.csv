model,arc_challenge_acc,arc_challenge_acc_norm,arc_easy_acc,arc_easy_acc_norm,boolq_acc,hellaswag_acc,hellaswag_acc_norm,lambada_openai_acc,lambada_openai_perplexity,openbookqa_acc,openbookqa_acc_norm,piqa_acc,piqa_acc_norm,winogrande_acc
qwen2.5_1.5b_nnlut,0.2142,0.2619,0.258,0.2542,0.3783,0.2561,0.2628,0.0,59067647.6953,0.152,0.292,0.5435,0.5218,0.4901
qwen2.5_3b_nnlut,0.227,0.2585,0.2496,0.2542,0.6217,0.2555,0.2642,0.0,5397345278.4439,0.156,0.282,0.5234,0.531,0.4917
smollm_3b_nnlut,0.2927,0.3259,0.3691,0.3573,0.6339,0.3338,0.4361,0.0163,1419735.4002,0.212,0.31,0.6066,0.5865,0.5848
